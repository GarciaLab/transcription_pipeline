{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Prepare Dataset and Specify Parameters (please only edit cells in this section)\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:15:38.498189Z",
     "start_time": "2025-02-20T00:15:38.493759Z"
    }
   },
   "source": [
    "# Parameters to specify\n",
    "\n",
    "# Specify here at what frame NC14 starts\n",
    "nc14_start_frame = 400\n",
    "\n",
    "# Any trace with frame number smaller than min_frames will be filtered out\n",
    "min_frames = 40\n",
    "\n",
    "# Number of bins you want to split the full embryo into\n",
    "num_bins = 42"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:15:40.708205Z",
     "start_time": "2025-02-20T00:15:40.705321Z"
    }
   },
   "source": [
    "# Dataset Directory\n",
    "\n",
    "dataset_folder = '/mnt/Data1/Nick/transcription_pipeline/'\n",
    "\n",
    "RBSPWM_datasets = [\n",
    "    \"test_data/2024-02-26/Halo-RBSPWM_embryo01\",\n",
    "    \"test_data/2024-02-26/Halo-RBSPWM_embryo02\",\n",
    "    \"test_data/2024-05-07/Halo552-RBSPWM_embryo01\",\n",
    "    \"test_data/2024-05-07/Halo552-RBSPWM_embryo02\",\n",
    "    \"test_data/2024-05-09/Halo552-RBSPWM_embryo01\",\n",
    "]\n",
    "\n",
    "RBSVar2_datasets = [\n",
    "    \"test_data/2024-07-23/Halo673_RBSVar2_embryo01\",\n",
    "    \"test_data/2024-07-25/Halo673_RBSVar2_embryo01\",\n",
    "    \"test_data/2024-10-10/Halo673_RBSVar2_embryo01\",\n",
    "    \"test_data/2024-10-10/Halo673_RBSVar2_embryo02\",\n",
    "]\n",
    "MCP_mSG_datasets = [\n",
    "    \"test_data/2024-10-31/MCP-mSG_ParB-mScar_RBSPWM_embryo01\",\n",
    "    \"test_data/2024-10-31/MCP-mSG_ParB-mScar_RBSPWM_embryo02\",\n",
    "    ]\n",
    "\n",
    "test_dataset_name = dataset_folder + RBSPWM_datasets[4]\n",
    "print('Dataset Path: ' + test_dataset_name)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: /mnt/Data1/Nick/transcription_pipeline/test_data/2024-05-09/Halo552-RBSPWM_embryo01\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:15:45.733469Z",
     "start_time": "2025-02-20T00:15:44.712078Z"
    }
   },
   "source": [
    "# Import pipeline\n",
    "from transcription_pipeline import nuclear_pipeline\n",
    "from transcription_pipeline import preprocessing_pipeline\n",
    "\n",
    "from transcription_pipeline import spot_pipeline\n",
    "from transcription_pipeline import fullEmbryo_pipeline\n",
    "\n",
    "from transcription_pipeline.spot_analysis import compile_data\n",
    "from transcription_pipeline.utils import plottable\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`JAVA_HOME` environment variable set to /mnt/Data1/Nick/miniforge3/envs/transcription_pipeline\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:15:49.819Z",
     "start_time": "2025-02-20T00:15:49.808880Z"
    }
   },
   "source": [
    "# Specify how you would want the plots to be shown: Use TkAgg if you use PyCharm, or widget if you use a browser\n",
    "\n",
    "mpl.use('TkAgg')\n",
    "# %matplotlib widget"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MS2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect whether the dataset has already been converted into `zarr` files, i.e. whether there's \"previously\" processed data. If so, load the previous results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:15:59.896227Z",
     "start_time": "2025-02-20T00:15:59.891619Z"
    }
   },
   "source": [
    "ms2_import_previous = os.path.isdir(test_dataset_name + '/collated_dataset')\n",
    "ms2_import_previous"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:16:01.543576Z",
     "start_time": "2025-02-20T00:16:01.540466Z"
    }
   },
   "source": [
    "dataset = preprocessing_pipeline.DataImport(\n",
    "    name_folder=test_dataset_name,\n",
    "    trim_series=True,\n",
    "    working_storage_mode='zarr',\n",
    "    import_previous=ms2_import_previous, \n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FullEmbryo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "FullEmbryo_dataset = preprocessing_pipeline.FullEmbryoImport(\n",
    "    name_folder=test_dataset_name,\n",
    "    #import_previous=True\n",
    ")\n",
    "# Loading FullEmbryo dataset is not working currently, but reported to Yovan where it only reads in the last channel\n",
    "# FullEmbryo_dataset.save()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a DASK Client for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "try:\n",
    "    cluster = LocalCluster(\n",
    "        host=\"localhost\",\n",
    "        scheduler_port=37763,\n",
    "        threads_per_worker=1,\n",
    "        n_workers=14,\n",
    "        memory_limit=\"6GB\",\n",
    "    )\n",
    "    \n",
    "    client = Client(cluster)\n",
    "except:\n",
    "    print(\"Cluster already running\")\n",
    "    client = Client('localhost:37763')\n",
    "\n",
    "print(client)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "client.restart()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "client"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclear Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect whether the nuclear tracking has been done \"previously.\" If so, load the previous results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:16:21.744765Z",
     "start_time": "2025-02-20T00:16:21.741978Z"
    }
   },
   "source": [
    "nuclear_tracking_previous = os.path.isdir(test_dataset_name + '/nuclear_analysis_results')\n",
    "nuclear_tracking_previous"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if nuclear_tracking_previous:\n",
    "    # Load nuclear tracking results\n",
    "    print('Load from previous nuclear tracking results')\n",
    "    \n",
    "    nuclear_tracking = nuclear_pipeline.Nuclear()\n",
    "    nuclear_tracking.read_results(name_folder=test_dataset_name)\n",
    "    \n",
    "else:\n",
    "    # Do nuclear tracking and save the results\n",
    "    print('Do nuclear tracking for the dataset')\n",
    "    \n",
    "    nuclear_tracking = nuclear_pipeline.Nuclear(\n",
    "        data=dataset.channels_full_dataset[0],\n",
    "        global_metadata=dataset.export_global_metadata[0],\n",
    "        frame_metadata=dataset.export_frame_metadata[0],\n",
    "        series_splits=dataset.series_splits,\n",
    "        series_shifts=dataset.series_shifts,\n",
    "        search_range_um=1.5,\n",
    "        stitch=False,\n",
    "        stitch_max_distance=4,\n",
    "        stitch_max_frame_distance=2,\n",
    "        client=client,\n",
    "        keep_futures=False,\n",
    "    )\n",
    "    \n",
    "    nuclear_tracking.track_nuclei(\n",
    "            working_memory_mode=\"zarr\",\n",
    "            working_memory_folder=test_dataset_name,\n",
    "            trackpy_log_path=\"\".join([test_dataset_name, \"trackpy_log\"]),\n",
    "        )\n",
    "        # Saves tracked nuclear mask as a zarr, and pickles dataframes with segmentation and\n",
    "        # tracking information.\n",
    "    nuclear_tracking.save_results(\n",
    "            name_folder=test_dataset_name, save_array_as=None\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect whether the spot tracking has been done \"previously.\" If so, load the previous results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:16:26.901250Z",
     "start_time": "2025-02-20T00:16:26.898240Z"
    }
   },
   "source": [
    "spot_tracking_previous = os.path.isdir(test_dataset_name + '/spot_analysis_results')\n",
    "spot_tracking_previous"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:16:30.144098Z",
     "start_time": "2025-02-20T00:16:28.581556Z"
    }
   },
   "source": [
    "%%time\n",
    "\n",
    "if spot_tracking_previous:\n",
    "    # Load spot tracking results\n",
    "    print('Load from spot tracking results')\n",
    "    \n",
    "    spot_tracking = spot_pipeline.Spot()\n",
    "    spot_tracking.read_results(name_folder=test_dataset_name)\n",
    "    \n",
    "else:\n",
    "    # Do spot tracking and save the results\n",
    "    print('Do spot tracking for the dataset')\n",
    "    \n",
    "    spot_tracking = spot_pipeline.Spot(\n",
    "        data=dataset.channels_full_dataset[1],\n",
    "        global_metadata=dataset.export_global_metadata[1],\n",
    "        frame_metadata=dataset.export_frame_metadata[1],\n",
    "        labels=None,#nuclear_tracking.reordered_labels,\n",
    "        expand_distance=3,\n",
    "        search_range_um=4.2,\n",
    "        retrack_search_range_um=4.5,\n",
    "        threshold_factor=1.3,\n",
    "        memory=3,\n",
    "        retrack_after_filter=False,\n",
    "        stitch=True,\n",
    "        min_track_length=0,\n",
    "        series_splits=dataset.series_splits,\n",
    "        series_shifts=dataset.series_shifts,\n",
    "        keep_bandpass=False,\n",
    "        keep_futures=False,\n",
    "        keep_spot_labels=False,\n",
    "        evaluate=True,\n",
    "        retrack_by_intensity=True,\n",
    "        client=client,\n",
    "    )\n",
    "    \n",
    "    spot_tracking.extract_spot_traces(\n",
    "        working_memory_folder=test_dataset_name, \n",
    "        stitch=True,\n",
    "        retrack_after_filter=True,\n",
    "        trackpy_log_path = test_dataset_name+'/trackpy_log'\n",
    "    )\n",
    "    \n",
    "    # Saves tracked spot mask as a zarr, and pickles dataframes with spot fitting and\n",
    "    # quantification information.\n",
    "    spot_tracking.save_results(name_folder=test_dataset_name, save_array_as=None)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from spot tracking results\n",
      "CPU times: user 1.28 s, sys: 283 ms, total: 1.56 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Compiled Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:16:37.750284Z",
     "start_time": "2025-02-20T00:16:35.465240Z"
    }
   },
   "source": [
    "# Load spot tracking dataframe\n",
    "spot_df = spot_tracking.spot_dataframe\n",
    "\n",
    "# Remove spots that were not detected\n",
    "detected_spots = spot_df[spot_df[\"particle\"] != 0]\n",
    "\n",
    "# Compile traces\n",
    "compiled_dataframe = compile_data.compile_traces(\n",
    "    detected_spots,\n",
    "    compile_columns_spot=[\n",
    "        \"frame\",\n",
    "        \"t_s\",\n",
    "        \"intensity_from_neighborhood\",\n",
    "        \"intensity_std_error_from_neighborhood\",\n",
    "        \"x\",\n",
    "        \"y\"\n",
    "    ],\n",
    "    nuclear_tracking_dataframe=None,\n",
    ")\n",
    "\n",
    "compiled_dataframe.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   particle                                              frame  \\\n",
       "0         2  [608, 609, 610, 613, 614, 615, 616, 617, 618, ...   \n",
       "1         3  [579, 580, 581, 582, 583, 584, 585, 586, 587, ...   \n",
       "2         4  [640, 641, 642, 643, 644, 645, 647, 648, 649, ...   \n",
       "3         5  [613, 614, 615, 616, 617, 618, 619, 620, 621, ...   \n",
       "4         6  [583, 585, 586, 588, 590, 591, 592, 593, 594, ...   \n",
       "\n",
       "                                                 t_s  \\\n",
       "0  [2981.271999359131, 2985.51900100708, 2989.767...   \n",
       "1  [2857.3950004577637, 2861.64400100708, 2865.89...   \n",
       "2  [3117.5319995880127, 3121.579999923706, 3126.1...   \n",
       "3  [3002.3190002441406, 3006.1590003967285, 3010....   \n",
       "4  [2874.9950008392334, 2883.492000579834, 2887.7...   \n",
       "\n",
       "                         intensity_from_neighborhood  \\\n",
       "0  [67.20298245614036, 62.61358125, 92.1778863636...   \n",
       "1  [368.71108000000004, 162.58609316770185, 207.0...   \n",
       "2  [137.8392151898734, 246.30097297297297, 162.72...   \n",
       "3  [223.98077931034484, 149.44997701149424, 102.1...   \n",
       "4  [56.80923595505618, 58.452866666666665, 56.477...   \n",
       "\n",
       "               intensity_std_error_from_neighborhood  \\\n",
       "0  [54.07608080882359, 53.08599141703332, 48.6846...   \n",
       "1  [48.961304741944936, 48.764177034702456, 49.24...   \n",
       "2  [50.04719298970737, 48.033152885448544, 53.299...   \n",
       "3  [52.019684703514685, 46.46238563874822, 49.753...   \n",
       "4  [45.10765132358713, 45.86984351271528, 48.0794...   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [706.3077781092006, 705.0800225329217, 704.078...   \n",
       "1  [814.23756413008, 814.0490753702337, 812.66835...   \n",
       "2  [610.5256101215496, 610.5078280423238, 610.170...   \n",
       "3  [789.4493998034413, 790.1299534943532, 790.754...   \n",
       "4  [830.0205022942665, 828.8195400854084, 827.835...   \n",
       "\n",
       "                                                   y  \n",
       "0  [132.22746686990476, 133.33576781054558, 131.9...  \n",
       "1  [165.32374456695854, 165.4022049366289, 164.15...  \n",
       "2  [200.09244408786026, 199.6949788757095, 200.19...  \n",
       "3  [111.42483044437226, 110.54379569293525, 110.3...  \n",
       "4  [152.07172254602511, 153.15739986339034, 152.5...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle</th>\n",
       "      <th>frame</th>\n",
       "      <th>t_s</th>\n",
       "      <th>intensity_from_neighborhood</th>\n",
       "      <th>intensity_std_error_from_neighborhood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[608, 609, 610, 613, 614, 615, 616, 617, 618, ...</td>\n",
       "      <td>[2981.271999359131, 2985.51900100708, 2989.767...</td>\n",
       "      <td>[67.20298245614036, 62.61358125, 92.1778863636...</td>\n",
       "      <td>[54.07608080882359, 53.08599141703332, 48.6846...</td>\n",
       "      <td>[706.3077781092006, 705.0800225329217, 704.078...</td>\n",
       "      <td>[132.22746686990476, 133.33576781054558, 131.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[579, 580, 581, 582, 583, 584, 585, 586, 587, ...</td>\n",
       "      <td>[2857.3950004577637, 2861.64400100708, 2865.89...</td>\n",
       "      <td>[368.71108000000004, 162.58609316770185, 207.0...</td>\n",
       "      <td>[48.961304741944936, 48.764177034702456, 49.24...</td>\n",
       "      <td>[814.23756413008, 814.0490753702337, 812.66835...</td>\n",
       "      <td>[165.32374456695854, 165.4022049366289, 164.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[640, 641, 642, 643, 644, 645, 647, 648, 649, ...</td>\n",
       "      <td>[3117.5319995880127, 3121.579999923706, 3126.1...</td>\n",
       "      <td>[137.8392151898734, 246.30097297297297, 162.72...</td>\n",
       "      <td>[50.04719298970737, 48.033152885448544, 53.299...</td>\n",
       "      <td>[610.5256101215496, 610.5078280423238, 610.170...</td>\n",
       "      <td>[200.09244408786026, 199.6949788757095, 200.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[613, 614, 615, 616, 617, 618, 619, 620, 621, ...</td>\n",
       "      <td>[3002.3190002441406, 3006.1590003967285, 3010....</td>\n",
       "      <td>[223.98077931034484, 149.44997701149424, 102.1...</td>\n",
       "      <td>[52.019684703514685, 46.46238563874822, 49.753...</td>\n",
       "      <td>[789.4493998034413, 790.1299534943532, 790.754...</td>\n",
       "      <td>[111.42483044437226, 110.54379569293525, 110.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[583, 585, 586, 588, 590, 591, 592, 593, 594, ...</td>\n",
       "      <td>[2874.9950008392334, 2883.492000579834, 2887.7...</td>\n",
       "      <td>[56.80923595505618, 58.452866666666665, 56.477...</td>\n",
       "      <td>[45.10765132358713, 45.86984351271528, 48.0794...</td>\n",
       "      <td>[830.0205022942665, 828.8195400854084, 827.835...</td>\n",
       "      <td>[152.07172254602511, 153.15739986339034, 152.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Embryo Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(FullEmbryo_dataset.channels_full_dataset_surf[0][0, :, :], cmap='gray')\n",
    "plt.title('Full Embryo Surf')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(FullEmbryo_dataset.channels_full_dataset_mid[0][0, :, :], cmap='gray')\n",
    "plt.title('Full Embryo Mid')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fullEmbryo = fullEmbryo_pipeline.FullEmbryo(FullEmbryo_dataset, dataset, his_channel=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fullEmbryo.find_ap_axis(make_plots=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "compiled_dataframe = fullEmbryo.xy_to_ap(compiled_dataframe)\n",
    "compiled_dataframe.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RateExtraction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Average"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:16:43.634090Z",
     "start_time": "2025-02-20T00:16:43.621618Z"
    }
   },
   "source": [
    "from transcription_pipeline.RateExtraction import FitAndAverage"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:18:14.225257Z",
     "start_time": "2025-02-20T00:16:46.458645Z"
    }
   },
   "source": [
    "faadata = FitAndAverage(compiled_dataframe, nc14_start_frame, 40, num_bins, test_dataset_name)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous particle trace fit checking results detected. Do particle trace fitting for the dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Data1/Nick/transcription_pipeline/transcription_pipeline/utils/plottable.py:17: UserWarning: Could not determine division time, using absolute time.\n",
      "  warnings.warn(\"Could not determine division time, using absolute time.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 547\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 606\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 310\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 150\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 465\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 38\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 360\n",
      "Failed to find derivative sign change for trace 20\n",
      "Failed to find derivative sign change for trace 450\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 623\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 173\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 218\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 30\n",
      "Failed to find derivative sign change for trace 143\n",
      "Failed to find derivative sign change for trace 32\n",
      "Failed to find derivative sign change for trace 690\n",
      "Failed to find derivative sign change for trace 604\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 24\n",
      "Failed to find derivative sign change for trace 46\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 82\n",
      "Failed to find derivative sign change for trace 939\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 580\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 367\n",
      "Failed to find derivative sign change for trace 389\n",
      "Failed to find derivative sign change for trace 724\n",
      "Failed to find derivative sign change for trace 343\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 694\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 64\n",
      "Failed to find derivative sign change for trace 992\n",
      "Failed to find derivative sign change for trace 487\n",
      "Failed to find derivative sign change for trace 919\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 36\n",
      "Failed to find derivative sign change for trace 316\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 356\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 250\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 539\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 80\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 97\n",
      "Failed to find derivative sign change for trace 763\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 645\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 19\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 3\n",
      "Failed to find derivative sign change for trace 956\n",
      "Failed to find derivative sign change for trace 963\n",
      "Warning: Least squares fitting failed. Message: The maximum number of function evaluations is exceeded.\n",
      "Failed to fit trace 395\n",
      "Number of traces: 231\n",
      "Number of traces with valid fits: 186\n",
      "Number of traces with invalid fits: 45\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:21:00.923168Z",
     "start_time": "2025-02-20T00:18:22.394348Z"
    }
   },
   "source": "faadata.check_particle_fits()",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "faadata.save_checked_particle_fits()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "faadata.average_particle_fits();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average and Fit"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from transcription_pipeline.RateExtraction import AverageAndFit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "time_bin_width = dataset.export_frame_metadata[0]['t_s'][1, 0]\n",
    "aafdata = AverageAndFit(compiled_dataframe, nc14_start_frame, time_bin_width, num_bins, test_dataset_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "aafdata.check_bin_fits()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "aafdata.bin_average_fit_dataframe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "aafdata.save_checked_bin_fits()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "aafdata.plot_bin_fits()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
